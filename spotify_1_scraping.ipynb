{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| [Main](index.ipynb) | [Part 2: Basic Exploration](spotify_2_basic_exploration.ipynb) >\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Scraping and Wrangling\n",
    "\n",
    "To begin our project, we first need to collect some data. We'll scrape a large number of music tracks (and their corresponding metrics) from [Spotify](https://www.spotify.com/), using their [Web API](https://developer.spotify.com/web-api/). To interface with this API, we'll use the convenient [spotipy](https://github.com/plamere/spotipy) Python library.\n",
    "\n",
    "We'll pull in tracks from [my personal Spotify library](https://open.spotify.com/user/nxbrnt/playlist/1ypVHzjgXq07PwQR7SBcGU?si=d56V5YZ-Q1y4FhiWzXN0gg) (~6000 tracks), and from the [Billboard Year-End Hot 100](https://en.wikipedia.org/wiki/Billboard_Hot_100) for every year since 1960 (~6000 tracks).\n",
    "\n",
    "We'll then filter, merge, and wrangle this data into a [pandas](https://pandas.pydata.org/) dataframe that is well-suited for exploration and &mdash; later &mdash; *classification*.\n",
    "\n",
    "*All of the prototyping and data exploration that went into the design of these scraping and wrangling functions is omitted here, but their functionality is discussed thoroughly as they are introduced below.*\n",
    "\n",
    "---\n",
    "\n",
    "First, let's do some standard imports, configure pandas to show more columns, and load in our API keys. To add in your own API keys, add them to keys.py, or create secret_keys.py and add them there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-14T19:34:53.358845Z",
     "start_time": "2017-12-14T19:34:20.379199Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spotipy\n",
    "import spotipy.util as util\n",
    "\n",
    "pd.options.display.max_columns = 50\n",
    "\n",
    "#Load Spotify API keys\n",
    "from keys import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Authorization\n",
    "\n",
    "Now, we need to obtain an authorization token from Spotify using spotipy. \n",
    "\n",
    "**Note**: The commented-out code at the top of the cell will write the contents of the cell (without executing the code) to the specified .py file (spotify_auth.py in this case). This will allow us to re-use these functions in later notebooks. An imported module can only use imports that are imported locally in said module, so we must include them explicitly when writing the file.\n",
    "\n",
    "---\n",
    "`spotify_auth` takes a dictionary of Spotify API credentials and returns a Spotify API object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-14T19:34:56.292935Z",
     "start_time": "2017-12-14T19:34:56.266931Z"
    }
   },
   "outputs": [],
   "source": [
    "# %%writefile spotify_auth.py\n",
    "# #Imports here for writefile magic only. Not Pythonic.\n",
    "# import pandas as pd\n",
    "# import spotipy\n",
    "# import spotipy.util as util\n",
    "\n",
    "def spotify_auth( auth_dict ):\n",
    "    \n",
    "    \"\"\"Obtain a Spotify authorization token\"\"\"\n",
    "    \n",
    "    client_id = auth_dict['client_id']\n",
    "    secret = auth_dict['secret']\n",
    "    redirect_uri = auth_dict['redirect_uri']\n",
    "    scope = auth_dict['scope']\n",
    "    username = auth_dict['username']\n",
    "\n",
    "    #If Chrome doesn't redirect, find redirect url using \n",
    "    #Chrome Developer Tools (Details TBA)\n",
    "    token = util.prompt_for_user_token(username, scope, client_id, secret, \n",
    "                                       redirect_uri)\n",
    "\n",
    "    if token:\n",
    "        sp = spotipy.Spotify(auth=token)\n",
    "        print('Successfully received auth token.')\n",
    "    else:\n",
    "        print('Cannot get token for' + username + '.')\n",
    "        return\n",
    "    \n",
    "    return sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Functions\n",
    "\n",
    "Our main scraping function - `scrape_playlist_dataframe` - wraps up a number of other functions defined below:\n",
    "\n",
    "- `scrape_playlist_raw` pulls all tracks from the playlist of interest. While doing so, it uses the resulting track ids to pull in each track's *audio features*, *artist info*, and *album info*, each using a separate API call. This data is sculpted a bit and returned as raw lists.\n",
    "\n",
    "- `tracks_dataframe` constructs a dataframe of tracks from the raw tracks list, and removes redundant columns.\n",
    "\n",
    "- `features_dataframe` fills missing raw feature dictionaries, converts the duration variable from milliseconds to minutes, and returns this as a dataframe with redundant columns dropped.\n",
    "\n",
    "- `artists_dataframe` pulls out the number of followers an artist has, and capitalizes the list of genres associated with the artist. Redundant columns are dropped and a dataframe is returned.\n",
    "\n",
    "- `albums_dataframe` converts the album's release date (string) into `'release_year'`, `'release_month'`, and `'release_day'` numerical variables. It then returns a dataframe with redundant columns dropped.\n",
    "\n",
    "`scrape_playlist_dataframe` then simply joins all of these dataframes and returns the result.\n",
    "\n",
    "---\n",
    "\n",
    "The different API requests can each return a different number of results:\n",
    "\n",
    "**Artists: 50, Albums: 20, TracksFromPlaylist: 100, Features: 100.**\n",
    "\n",
    "In order to pull all results in a single loop, we simply limit the number of results from all calls to the minimum (20). We could pull all of our data with roughly half the number of calls if we allowed for a different number of results from each, but this keeps our code simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-14T19:35:00.392818Z",
     "start_time": "2017-12-14T19:34:59.619774Z"
    }
   },
   "outputs": [],
   "source": [
    "# %%writefile scrape_playlist_dataframe.py\n",
    "# #Imports here for writefile magic only. Not Pythonic.\n",
    "# import pandas as pd\n",
    "# import spotipy\n",
    "# import spotipy.util as util\n",
    "\n",
    "def scrape_playlist_raw(sp, username, playlist_id):\n",
    "    \n",
    "    #Scrape tracks\n",
    "    results = sp.user_playlist_tracks(username, playlist_id, limit=20) \n",
    "    \n",
    "    tracks = [ x['track'] for x in results['items'] ]\n",
    "    \n",
    "    results_ids = [ x['id'] for x in tracks ]\n",
    "    features = sp.audio_features( results_ids )\n",
    "    \n",
    "    #This only pulls first artist id per track for now.\n",
    "    results_ids_artist = [ x['artists'][0]['id'] for x in tracks ] \n",
    "    artists = sp.artists( results_ids_artist )['artists']\n",
    "    results_ids_album = [ x['album']['id'] for x in tracks ]\n",
    "    albums = sp.albums( results_ids_album )['albums']\n",
    "    \n",
    "    while results['next']:\n",
    "        \n",
    "        results = sp.next(results)\n",
    "        \n",
    "        #Pull track, audio, artist, and album info, using separate API calls\n",
    "        results_tracks = [ x['track'] for x in results['items'] ]\n",
    "        results_ids = [ x['id'] for x in results_tracks ]\n",
    "        results_features = sp.audio_features( results_ids )\n",
    "        results_ids_artist = [ x['artists'][0]['id'] for x in results_tracks ]\n",
    "        results_artists = sp.artists( results_ids_artist )['artists']\n",
    "        results_ids_album = [ x['album']['id'] for x in results_tracks ]\n",
    "        results_albums = sp.albums( results_ids_album )['albums']\n",
    "        \n",
    "        tracks.extend( results_tracks )\n",
    "        features.extend( results_features )\n",
    "        artists.extend( results_artists )\n",
    "        albums.extend( results_albums )\n",
    "    \n",
    "    return tracks, features, artists, albums\n",
    "\n",
    "\n",
    "def tracks_dataframe(tracks):\n",
    "    #Construct tracks dataframe\n",
    "    df_tracks = pd.DataFrame(tracks)\n",
    "\n",
    "    #Drop unwanted columns\n",
    "    cols = ['album', 'artists', 'duration_ms', 'external_ids', 'external_urls',\n",
    "            'href', 'type', 'uri'] \n",
    "    df_tracks.drop(cols, axis=1, inplace=True)\n",
    "    \n",
    "    return df_tracks\n",
    "\n",
    "\n",
    "def features_dataframe(features, ids):\n",
    "    \n",
    "    \"\"\"\n",
    "    ids need to be specified in order to fill the 'id' field in missing dicts\n",
    "    \"\"\"\n",
    "    \n",
    "    #Fill missing feature dicts\n",
    "    #This uses the first dictionary in the list as a template\n",
    "    #*Assumes first dictionary isn't missing.*\n",
    "    none_dict = { key:None for key in features[0] }\n",
    "    for i,x in enumerate(features):\n",
    "        if x is None:\n",
    "            none_dict['id'] = ids[i]\n",
    "            features[i] = none_dict\n",
    "    \n",
    "    #Construct features dataframe    \n",
    "    df_features = pd.DataFrame(features)\n",
    "\n",
    "    #Convert duration from milliseconds to minutes\n",
    "    df_features['duration_mins'] = df_features['duration_ms']/60000\n",
    "    \n",
    "    #Drop unwanted columns\n",
    "    cols = ['id', 'analysis_url', 'track_href', 'type', 'uri', 'duration_ms']\n",
    "    df_features.drop(cols, axis=1, inplace=True)\n",
    "    \n",
    "    return df_features\n",
    "    \n",
    "def artists_dataframe(artists):\n",
    "    #Construct tracks dataframe\n",
    "    df_artists = pd.DataFrame(artists)\n",
    "    \n",
    "    #Pull total number of followers from 'followers' dictionary\n",
    "    df_artists['num_followers'] = df_artists['followers'].transform( \n",
    "        lambda x: x['total'] )\n",
    "    \n",
    "    #Capitalize genre names\n",
    "    def strings_to_titles(list_of_strings):\n",
    "        return [string.title() for string in list_of_strings]\n",
    "    df_artists['genres'] = df_artists.genres.transform( \n",
    "        lambda x: strings_to_titles(x) )\n",
    "    \n",
    "    #Drop unwanted columns\n",
    "    cols = ['num_followers','genres','images','name','popularity','id']\n",
    "    df_artists = df_artists[cols]\n",
    "    \n",
    "    return df_artists\n",
    "\n",
    "def albums_dataframe(albums):\n",
    "    #Construct tracks dataframe\n",
    "    df_albums = pd.DataFrame(albums)\n",
    "    \n",
    "    #Construct integer release year column\n",
    "    df_albums['release_year'] = df_albums.release_date.str[0:4].astype('int')\n",
    "    \n",
    "    #Float month/day columns. To allow for missing (NaN) info\n",
    "    df_albums['release_month'] = pd.to_numeric( \n",
    "        df_albums.release_date.str[5:7], errors='coerce')\n",
    "    df_albums['release_day'] = pd.to_numeric( \n",
    "        df_albums.release_date.str[8:10], errors='coerce')\n",
    "    \n",
    "    #Drop unwanted columns\n",
    "    cols = ['album_type', 'images', 'label', 'name', 'popularity', \n",
    "            'release_year', 'release_month', 'release_day']\n",
    "    df_albums = df_albums[cols]\n",
    "    \n",
    "    return df_albums\n",
    "    \n",
    "def scrape_playlist_dataframe(sp, username, playlist_id):\n",
    "    \n",
    "    #Scrape tracks, features, artists, albums as lists, derive ids\n",
    "    tracks, features, artists, albums = scrape_playlist_raw(sp, username, \n",
    "                                                            playlist_id)\n",
    "    ids = [ x['id'] for x in tracks ]\n",
    "    \n",
    "    #Build tracks and features dataframes\n",
    "    df_tracks = tracks_dataframe(tracks)\n",
    "    df_features = features_dataframe(features, ids)\n",
    "    df_artists = artists_dataframe(artists)\n",
    "    df_albums = albums_dataframe(albums)\n",
    "    \n",
    "    #Join into one dataframe\n",
    "    df = df_tracks.join(df_features).join(df_artists, rsuffix='_artist').join(\n",
    "        df_albums, rsuffix='_album')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above functions allow us to construct a nicely structured dataframe from *any* Spotify playlist. In order to construct our complete dataset, we will pull a number of playlists and combine them into one dataframe.\n",
    "\n",
    "---\n",
    "\n",
    "- `scrape_all_playlists` scrapes a playlist full of tracks from my personal music library, as well as 6 more dataframes of Billboard Hot 100 tracks (one playlist per decade). \n",
    "\n",
    "*Note: These Billboard playlists were constructed *partially* by hand, so there will be some false positive or missing tracks.*\n",
    "\n",
    "These dataframes are merged, keeping track of which dataset they belong to (the `'ds'` column) and what decade the Billboard tracks belong to (the `'decade'` column). We also add a dummy column for certain plotting functions that need it, and we remove all columns that won't be utilized in this project, including album images and preview urls.\n",
    "\n",
    "In addition, we pull in a playlist of tracks from Wesley Willis' discography. More on that later.\n",
    "\n",
    "Finally, the resulting dataframes are stored in hdf format. This is much faster than csv and can handle certain object columns that csv cannot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-14T19:35:05.431080Z",
     "start_time": "2017-12-14T19:35:05.266021Z"
    }
   },
   "outputs": [],
   "source": [
    "def scrape_all_playlists( auth_dict ):\n",
    "     \n",
    "    #Obtain Spotify auth token    \n",
    "    sp = spotify_auth( auth_dict )\n",
    "    #If no token obtained, return.\n",
    "    if sp is None:\n",
    "        return\n",
    "\n",
    "    #Tracks from my personal library that I managed to find on Spotify\n",
    "    df_nix = scrape_playlist_dataframe(\n",
    "        sp, username='nxbrnt', playlist_id='1ypVHzjgXq07PwQR7SBcGU')\n",
    "\n",
    "    #Wesley Willis' discography on Spotify.\n",
    "    df_ww = scrape_playlist_dataframe(\n",
    "        sp, username='nxbrnt', playlist_id='5IElZsqCmr3gilbBSLLl78')\n",
    "\n",
    "    #Around 90% of Billboard Hot 100 from 1960-2016. Split by decade \n",
    "    #(approximately 1000 tracks each).\n",
    "    df_10 = scrape_playlist_dataframe(\n",
    "        sp, username='nxbrnt', playlist_id='0Nqyr374lO74EpslPB42tW')\n",
    "    df_00 = scrape_playlist_dataframe(\n",
    "        sp, username='nxbrnt', playlist_id='0h8U2fFoxj4s2f67reBIc1')\n",
    "    df_90 = scrape_playlist_dataframe(\n",
    "        sp, username='nxbrnt', playlist_id='68yLpbpfFWs4pyqaPbfIpi')\n",
    "    df_80 = scrape_playlist_dataframe(\n",
    "        sp, username='nxbrnt', playlist_id='0eRDNZ0O3h1P2FRQYoy4CC')\n",
    "    df_70 = scrape_playlist_dataframe(\n",
    "        sp, username='nxbrnt', playlist_id='32CwVeir8S150tjZqWd4Od')\n",
    "    df_60 = scrape_playlist_dataframe(\n",
    "        sp, username='nxbrnt', playlist_id='0R2UZF1KlHgbw3WKTD1KDm')\n",
    "\n",
    "    #Add decade column to Billboard dataframes, and \n",
    "    #concatenate them into one dataframe.\n",
    "    df_10['decade'] = 2010\n",
    "    df_00['decade'] = 2000\n",
    "    df_90['decade'] = 1990\n",
    "    df_80['decade'] = 1980\n",
    "    df_70['decade'] = 1970\n",
    "    df_60['decade'] = 1960\n",
    "    df_top = pd.concat([df_10,df_00,df_90,df_80,df_70,df_60]).reset_index(\n",
    "        drop=True)\n",
    "\n",
    "    #Add dataset indicator column, and concatenate df_nix and df_top\n",
    "    df_nix['ds']='nix'\n",
    "    df_top['ds']='top'\n",
    "    df = pd.concat([df_nix,df_top]).reset_index(drop=True)\n",
    "\n",
    "    #Construct a uniform variable to use as \n",
    "    #a dummy in certain plot functions\n",
    "    df[''] = ''\n",
    "    df_ww[''] = ''\n",
    "\n",
    "    #Pull out (currently) unused columns into separate dataframes\n",
    "    cols = ['available_markets','preview_url','images','images_album']\n",
    "    df_extra = df[cols]\n",
    "    df.drop(cols, axis=1, inplace=True)\n",
    "    df_ww_extra = df_ww[cols]\n",
    "    df_ww.drop(cols, axis=1, inplace=True)\n",
    "\n",
    "    #Write dataframes to hdf. Much faster than csv, \n",
    "    #and csv screws up certain object columns.\n",
    "    df.to_hdf('./data/df.h5', 'main')\n",
    "    df_extra.to_hdf('./data/df.h5', 'extra')\n",
    "    df_ww.to_hdf('./data/df_ww.h5', 'main')\n",
    "    df_ww_extra.to_hdf('./data/df_ww.h5', 'extra')\n",
    "    \n",
    "    return df, df_ww"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping and Loading our Datasets\n",
    "\n",
    "From this point on, we will simply load our dataframes from their respective h5 files. We can uncomment the code at the top of the following cell when we want to re-scrape our datasets. Make sure to include valid API keys either here, in `keys.py`, or in `secret_keys.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-14T19:50:28.561990Z",
     "start_time": "2017-12-14T19:35:31.649608Z"
    }
   },
   "outputs": [],
   "source": [
    "# #Only uncomment and run this when re-scraping datasets\n",
    "# auth_dict = { 'client_id' : client_id,\n",
    "#               'secret' : secret,\n",
    "#               'redirect_uri' : redirect_uri,\n",
    "#               'scope' : 'user-library-read',\n",
    "#               'username' : username }\n",
    "# df,df_ww = scrape_all_playlists(auth_dict);\n",
    "\n",
    "df = pd.read_hdf('./data/df.h5', 'main')\n",
    "df_ww = pd.read_hdf('./data/df_ww.h5', 'main')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at our dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-14T19:51:26.640194Z",
     "start_time": "2017-12-14T19:51:26.567190Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 11540 entries, 0 to 11539\n",
      "Data columns (total 34 columns):\n",
      "acousticness         11539 non-null float64\n",
      "album_type           11540 non-null object\n",
      "danceability         11539 non-null float64\n",
      "decade               5320 non-null float64\n",
      "disc_number          11540 non-null int64\n",
      "ds                   11540 non-null object\n",
      "duration_mins        11539 non-null float64\n",
      "energy               11539 non-null float64\n",
      "explicit             11540 non-null bool\n",
      "genres               11540 non-null object\n",
      "id                   11540 non-null object\n",
      "id_artist            11540 non-null object\n",
      "instrumentalness     11539 non-null float64\n",
      "key                  11539 non-null float64\n",
      "label                11540 non-null object\n",
      "liveness             11539 non-null float64\n",
      "loudness             11539 non-null float64\n",
      "mode                 11539 non-null float64\n",
      "name                 11540 non-null object\n",
      "name_album           11540 non-null object\n",
      "name_artist          11540 non-null object\n",
      "num_followers        11540 non-null int64\n",
      "popularity           11540 non-null int64\n",
      "popularity_album     11540 non-null int64\n",
      "popularity_artist    11540 non-null int64\n",
      "release_day          8991 non-null float64\n",
      "release_month        9045 non-null float64\n",
      "release_year         11540 non-null int32\n",
      "speechiness          11539 non-null float64\n",
      "tempo                11539 non-null float64\n",
      "time_signature       11539 non-null float64\n",
      "track_number         11540 non-null int64\n",
      "valence              11539 non-null float64\n",
      "                     11540 non-null object\n",
      "dtypes: bool(1), float64(16), int32(1), int64(6), object(10)\n",
      "memory usage: 3.0+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acousticness</th>\n",
       "      <th>album_type</th>\n",
       "      <th>danceability</th>\n",
       "      <th>decade</th>\n",
       "      <th>disc_number</th>\n",
       "      <th>ds</th>\n",
       "      <th>duration_mins</th>\n",
       "      <th>energy</th>\n",
       "      <th>explicit</th>\n",
       "      <th>genres</th>\n",
       "      <th>id</th>\n",
       "      <th>id_artist</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>label</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>name</th>\n",
       "      <th>name_album</th>\n",
       "      <th>name_artist</th>\n",
       "      <th>num_followers</th>\n",
       "      <th>popularity</th>\n",
       "      <th>popularity_album</th>\n",
       "      <th>popularity_artist</th>\n",
       "      <th>release_day</th>\n",
       "      <th>release_month</th>\n",
       "      <th>release_year</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>track_number</th>\n",
       "      <th>valence</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3613</th>\n",
       "      <td>0.000844</td>\n",
       "      <td>album</td>\n",
       "      <td>0.479</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>nix</td>\n",
       "      <td>5.818433</td>\n",
       "      <td>0.9950</td>\n",
       "      <td>False</td>\n",
       "      <td>[Power Noise]</td>\n",
       "      <td>52e0nh25QEkGAquu2Rvkyq</td>\n",
       "      <td>6NmVthYxYQNCeKst1we0fz</td>\n",
       "      <td>0.268</td>\n",
       "      <td>9.0</td>\n",
       "      <td>HANDS</td>\n",
       "      <td>0.6120</td>\n",
       "      <td>-6.654</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Where the Deep Grass Grows</td>\n",
       "      <td>Oto</td>\n",
       "      <td>Mono No Aware</td>\n",
       "      <td>624</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.2710</td>\n",
       "      <td>137.982</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1320</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2481</th>\n",
       "      <td>0.972000</td>\n",
       "      <td>album</td>\n",
       "      <td>0.363</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>nix</td>\n",
       "      <td>5.654000</td>\n",
       "      <td>0.0492</td>\n",
       "      <td>False</td>\n",
       "      <td>[Art Rock, Dance Rock, Electronic, Industrial,...</td>\n",
       "      <td>2spKqhUKZodGKhdwShWnRv</td>\n",
       "      <td>5KQMtyPE8DCQNUzoNqlEsE</td>\n",
       "      <td>0.200</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Beggars Banquet</td>\n",
       "      <td>0.0968</td>\n",
       "      <td>-21.256</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Please Push No More</td>\n",
       "      <td>Telekon</td>\n",
       "      <td>Gary Numan</td>\n",
       "      <td>104713</td>\n",
       "      <td>17</td>\n",
       "      <td>37</td>\n",
       "      <td>56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1979</td>\n",
       "      <td>0.0375</td>\n",
       "      <td>182.826</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.2720</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2296</th>\n",
       "      <td>0.009330</td>\n",
       "      <td>single</td>\n",
       "      <td>0.565</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>nix</td>\n",
       "      <td>3.093750</td>\n",
       "      <td>0.8730</td>\n",
       "      <td>False</td>\n",
       "      <td>[Bass Music, Electronic Trap, Glitch Hop, Vapo...</td>\n",
       "      <td>0hiiRAYYxZxJRnaQwGDl3a</td>\n",
       "      <td>2c2X6dr1PHctH24BxNOjHi</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>EPROM</td>\n",
       "      <td>0.3590</td>\n",
       "      <td>-6.151</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Brixton</td>\n",
       "      <td>Samurai</td>\n",
       "      <td>Eprom</td>\n",
       "      <td>18883</td>\n",
       "      <td>19</td>\n",
       "      <td>33</td>\n",
       "      <td>44</td>\n",
       "      <td>29.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.7020</td>\n",
       "      <td>128.364</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3540</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3147</th>\n",
       "      <td>0.000009</td>\n",
       "      <td>album</td>\n",
       "      <td>0.484</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>nix</td>\n",
       "      <td>6.391783</td>\n",
       "      <td>0.6780</td>\n",
       "      <td>False</td>\n",
       "      <td>[Aggrotech, Dark Wave, Ebm, Electro-Industrial...</td>\n",
       "      <td>3dD7I8fpBTd1LFSZhKim5P</td>\n",
       "      <td>0klcoRwPQF1GMv8FrA7F8V</td>\n",
       "      <td>0.884</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Cleopatra Records</td>\n",
       "      <td>0.1310</td>\n",
       "      <td>-14.570</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Prying Eyes</td>\n",
       "      <td>Underneath The Laughter</td>\n",
       "      <td>Leæther Strip</td>\n",
       "      <td>5706</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1994</td>\n",
       "      <td>0.0285</td>\n",
       "      <td>131.632</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0482</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8577</th>\n",
       "      <td>0.000889</td>\n",
       "      <td>album</td>\n",
       "      <td>0.671</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>1</td>\n",
       "      <td>top</td>\n",
       "      <td>3.978450</td>\n",
       "      <td>0.8620</td>\n",
       "      <td>False</td>\n",
       "      <td>[Bubblegum Dance, Eurodance, Europop, German T...</td>\n",
       "      <td>13vDH7LlES2hajU7yR07Mz</td>\n",
       "      <td>2vRfKzjQYJQd67X8x49MOh</td>\n",
       "      <td>0.700</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Hansa</td>\n",
       "      <td>0.1670</td>\n",
       "      <td>-11.367</td>\n",
       "      <td>1.0</td>\n",
       "      <td>One More Time</td>\n",
       "      <td>One More Time</td>\n",
       "      <td>Real McCoy</td>\n",
       "      <td>26883</td>\n",
       "      <td>32</td>\n",
       "      <td>29</td>\n",
       "      <td>51</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1997</td>\n",
       "      <td>0.0351</td>\n",
       "      <td>133.117</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8550</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      acousticness album_type  danceability  decade  disc_number   ds  \\\n",
       "3613      0.000844      album         0.479     NaN            1  nix   \n",
       "2481      0.972000      album         0.363     NaN            1  nix   \n",
       "2296      0.009330     single         0.565     NaN            1  nix   \n",
       "3147      0.000009      album         0.484     NaN            1  nix   \n",
       "8577      0.000889      album         0.671  1990.0            1  top   \n",
       "\n",
       "      duration_mins  energy  explicit  \\\n",
       "3613       5.818433  0.9950     False   \n",
       "2481       5.654000  0.0492     False   \n",
       "2296       3.093750  0.8730     False   \n",
       "3147       6.391783  0.6780     False   \n",
       "8577       3.978450  0.8620     False   \n",
       "\n",
       "                                                 genres  \\\n",
       "3613                                      [Power Noise]   \n",
       "2481  [Art Rock, Dance Rock, Electronic, Industrial,...   \n",
       "2296  [Bass Music, Electronic Trap, Glitch Hop, Vapo...   \n",
       "3147  [Aggrotech, Dark Wave, Ebm, Electro-Industrial...   \n",
       "8577  [Bubblegum Dance, Eurodance, Europop, German T...   \n",
       "\n",
       "                          id               id_artist  instrumentalness  key  \\\n",
       "3613  52e0nh25QEkGAquu2Rvkyq  6NmVthYxYQNCeKst1we0fz             0.268  9.0   \n",
       "2481  2spKqhUKZodGKhdwShWnRv  5KQMtyPE8DCQNUzoNqlEsE             0.200  5.0   \n",
       "2296  0hiiRAYYxZxJRnaQwGDl3a  2c2X6dr1PHctH24BxNOjHi             0.000  5.0   \n",
       "3147  3dD7I8fpBTd1LFSZhKim5P  0klcoRwPQF1GMv8FrA7F8V             0.884  2.0   \n",
       "8577  13vDH7LlES2hajU7yR07Mz  2vRfKzjQYJQd67X8x49MOh             0.700  5.0   \n",
       "\n",
       "                  label  liveness  loudness  mode                        name  \\\n",
       "3613              HANDS    0.6120    -6.654   1.0  Where the Deep Grass Grows   \n",
       "2481    Beggars Banquet    0.0968   -21.256   1.0         Please Push No More   \n",
       "2296              EPROM    0.3590    -6.151   0.0                     Brixton   \n",
       "3147  Cleopatra Records    0.1310   -14.570   1.0                 Prying Eyes   \n",
       "8577              Hansa    0.1670   -11.367   1.0               One More Time   \n",
       "\n",
       "                   name_album    name_artist  num_followers  popularity  \\\n",
       "3613                      Oto  Mono No Aware            624           1   \n",
       "2481                  Telekon     Gary Numan         104713          17   \n",
       "2296                  Samurai          Eprom          18883          19   \n",
       "3147  Underneath The Laughter  Leæther Strip           5706           1   \n",
       "8577            One More Time     Real McCoy          26883          32   \n",
       "\n",
       "      popularity_album  popularity_artist  release_day  release_month  \\\n",
       "3613                 4                  3          3.0           11.0   \n",
       "2481                37                 56          NaN            NaN   \n",
       "2296                33                 44         29.0            7.0   \n",
       "3147                 6                 28          NaN            NaN   \n",
       "8577                29                 51         25.0            3.0   \n",
       "\n",
       "      release_year  speechiness    tempo  time_signature  track_number  \\\n",
       "3613          2017       0.2710  137.982             4.0             2   \n",
       "2481          1979       0.0375  182.826             4.0            10   \n",
       "2296          2016       0.7020  128.364             4.0             3   \n",
       "3147          1994       0.0285  131.632             4.0             6   \n",
       "8577          1997       0.0351  133.117             3.0             1   \n",
       "\n",
       "      valence    \n",
       "3613   0.1320    \n",
       "2481   0.2720    \n",
       "2296   0.3540    \n",
       "3147   0.0482    \n",
       "8577   0.8550    "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info()\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End\n",
    "Now... Let's explore the data! [Part 2: Basic Exploration](spotify_2_basic_exploration.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "| [Main](index.ipynb) | [Part 2: Basic Exploration](spotify_2_basic_exploration.ipynb) >"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "notify_time": "10",
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "174px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "threshold": 4,
   "toc_cell": false,
   "toc_position": {
    "height": "853px",
    "left": "0px",
    "right": "1644px",
    "top": "106px",
    "width": "360px"
   },
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "278px",
    "left": "1550px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
